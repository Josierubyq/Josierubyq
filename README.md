#  Hi, I'm **Zhang Qian (Josie)**
* Machine Learning 路 Multimodal Large Models 路 Human-Inspired AI Understanding *
---

##  About Me
I have always been curious about a simple question:
Why do humans understand so well, yet machinesdespite their scalestill dont?

Modern models, even large ones, often rely on
surface-level correlations, dense representations, or pattern matching.
Their internal states rarely reflect the kind of organized, explainable knowledge that supports human reasoning.

My research goal is to explore how machine learning systems can develop
more structured, interpretable, and multimodal forms of understanding,
and to design model and agent architectures that better approximate how humans organize information.

This motivation drives all the directions I work in.

I am a final-year CS student at Ritsumeikan University (Osaka, Japan).

Currently a visiting student at **CUHK**, working on **multiagent prompt optimization**, neural bandits, and LLM workflow optimization.

---

##  Research Interests
- Multimodal video understanding, structured video representations  
- LLM agents, prompt & structure optimization  
- Representation learning, causal reasoning  
- Multimodal models

---

#  Publications
- **CnPBERT: Facilitating Chinese Online Petition Classification through Domain-Specific Pretraining**  
  *BDEE 2025* *In print*

---

#  Tech Stack
**Python**, PyTorch, Transformers  
**JavaScript**, React, React Three Fiber  
Unity (C#), Blender  
CUDA 路 NLP 路 CV 路 Generative AI

---
